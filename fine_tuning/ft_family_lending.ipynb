{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6253d0",
   "metadata": {},
   "source": [
    "# Family Lending Fine-Tuning Notebook\n",
    "This notebook prepares and fine-tunes an LLM on internal family lending dataset examples.\n",
    "\n",
    "**Sections**:\n",
    "1. Environment & Dependencies\n",
    "2. Data Loading & Cleaning\n",
    "3. Exploratory Stats / Quality Checks\n",
    "4. Formatting for Fine-Tuning (JSONL)\n",
    "5. Training / API Fine-Tune Job Submission\n",
    "6. Evaluation & Error Analysis\n",
    "7. Save Artifacts / Outputs\n",
    "\n",
    "> Keep raw source data out of git (already ignored via fine_tuning/raw & datasets/raw)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6dae8c",
   "metadata": {},
   "source": [
    "## 1. Environment & Dependencies\n",
    "Sets up directories, imports libraries, and confirms the working environment so later steps (data loading, generation, and fine‑tune) run predictably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment & Dependencies\n",
    "import os, json, pandas as pd, pathlib, datetime as dt\n",
    "from typing import Dict, List\n",
    "DATA_DIR = pathlib.Path('datasets')\n",
    "RAW_DIR = DATA_DIR / 'raw'  # git-ignored\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "PROCESSED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print('Working directory:', os.getcwd())\n",
    "print('Data dir exists:', DATA_DIR.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15c71c",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Cleaning\n",
    "Loads any real seed data (if present) from datasets/raw. Currently a placeholder; safe to skip if only using synthetic generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538dfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading & Cleaning (placeholder)\n",
    "# Replace with real load logic. Example expects a CSV in datasets/raw/family_lending_dataset.csv\n",
    "csv_path = RAW_DIR / 'family_lending_dataset.csv'\n",
    "if csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print('Loaded rows:', len(df))\n",
    "    # Minimal clean example\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "else:\n",
    "    print('CSV not found at', csv_path)\n",
    "    df = pd.DataFrame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae951f",
   "metadata": {},
   "source": [
    "## 3. Exploratory Stats / Quality Checks\n",
    "Basic EDA on any real loaded data. Skips automatically if no dataset is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exploratory Stats / Quality Checks (placeholder)\n",
    "if not df.empty:\n",
    "    display(df.describe(include='all').transpose())\n",
    "    print('Null counts:')\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print('DataFrame empty; skipping EDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc02dd0",
   "metadata": {},
   "source": [
    "## 4. Synthetic Chat Dataset Generation\n",
    "Creates 3,000 structured chat examples (train/val split 80/20) following the approved schema for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ab643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Synthetic Dataset Generation (chat-format JSONL) per agreed spec\n",
    "import random, math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "TOTAL = 3000\n",
    "SPLIT_TRAIN = 0.80\n",
    "# Class counts (fixed)\n",
    "counts = {\n",
    "    ('approved', True): 900,    # gift approved\n",
    "    ('approved', False): 1800,  # loan approved\n",
    "    ('declined', False): 150,\n",
    "    ('pending', False): 150,\n",
    "}\n",
    "# Sanity check\n",
    "assert sum(counts.values()) == TOTAL, 'Counts do not sum to TOTAL'\n",
    "\n",
    "purpose_categories = [\n",
    "    'medical','education','housing','emergency','small business','travel','debt consolidation',\n",
    "    'celebrations','vehicle','childcare','groceries','lunch','breakfast','dinner','gas money'\n",
    "]\n",
    "relationships = ['mother','father','sister','brother','aunt','uncle','cousin','niece','nephew','grandparent','in-law','close friend']\n",
    "\n",
    "# Amount ranges & distributions\n",
    "# Gifts: micro 40%, everyday 40%, special 20%\n",
    "gift_ranges = [\n",
    "    ('micro', 10, 40, 0.40),\n",
    "    ('everyday', 40, 120, 0.40),\n",
    "    ('special', 120, 250, 0.20),\n",
    "]\n",
    "# Non-gift loan buckets with distribution: light 35%, medium 50%, larger 14%, upper 1%\n",
    "loan_ranges = [\n",
    "    ('light', 150, 600, 0.35),\n",
    "    ('medium', 600, 2000, 0.50),\n",
    "    ('larger', 2000, 6000, 0.14),\n",
    "    ('upper', 6000, 10000, 0.01),\n",
    "]\n",
    "\n",
    "# Interest: include small symbolic interest (1-3%) in <=5% of non-gift loans\n",
    "INTEREST_RATE_PROB = 0.05\n",
    "\n",
    "# Helper weighted choice\n",
    "def weighted_choice(ranges):\n",
    "    r = random.random()\n",
    "    cumulative = 0\n",
    "    for name, lo, hi, w in ranges:\n",
    "        cumulative += w\n",
    "        if r <= cumulative:\n",
    "            return name, random.randint(lo, hi // 10) * 10  # round to nearest $10\n",
    "    # fallback last\n",
    "    name, lo, hi, w = ranges[-1]\n",
    "    return name, random.randint(lo, hi // 10) * 10\n",
    "\n",
    "empathy_openers = [\n",
    "    \"I appreciate you reaching out and being open about the need.\",\n",
    "    \"Thanks for trusting me with this—family support matters.\",\n",
    "    \"I hear you and want to help in a way that feels respectful.\",\n",
    "    \"You did the right thing by asking early so we can set gentle expectations.\",\n",
    "    \"I’m glad you felt comfortable sharing this situation.\",\n",
    "]\n",
    "positive_reassurance = [\n",
    "    \"Let’s keep this supportive, not stressful.\",\n",
    "    \"We’ll structure it so it stays manageable.\",\n",
    "    \"I want this to feel like partnership, not pressure.\",\n",
    "    \"We’ll keep communication open and flexible.\",\n",
    "]\n",
    "\n",
    "decline_warmth = [\n",
    "    \"I care about you and this isn’t a rejection of your need.\",\n",
    "    \"I wish I could say yes this time—please keep me in the loop.\",\n",
    "    \"This is a timing issue on my side, not a lack of support.\",\n",
    "]\n",
    "\n",
    "pending_warmth = [\n",
    "    \"I just need a little more clarity before finalizing.\",\n",
    "    \"Let me review my upcoming commitments and circle back shortly.\",\n",
    "    \"I want to help; I just need to confirm a couple details first.\",\n",
    "]\n",
    "\n",
    "reminder_styles = [\n",
    "    'gentle monthly check-ins','milestone reminders only','proactive but low-pressure','biweekly friendly note','quarterly recap'\n",
    "]\n",
    "\n",
    "def choose_amount(gift: bool, purpose: str):\n",
    "    if gift:\n",
    "        # Purpose heuristic: meals/gas -> micro bias\n",
    "        if purpose in ['lunch','breakfast','dinner','gas money','groceries']:\n",
    "            # Increase chance of micro\n",
    "            micro = [r for r in gift_ranges if r[0]=='micro'][0]\n",
    "            name, lo, hi, w = micro\n",
    "            return random.randint(lo, hi)  # keep small granular\n",
    "        name, amt = weighted_choice(gift_ranges)\n",
    "        return amt\n",
    "    # Non gift loan\n",
    "    # Purpose-based overrides\n",
    "    if purpose in ['lunch','breakfast','dinner','gas money','groceries']:\n",
    "        # light cap\n",
    "        return random.randint(150, 300)\n",
    "    if purpose in ['education','medical','vehicle','housing','small business','debt consolidation']:\n",
    "        bucket, amt = weighted_choice(loan_ranges)\n",
    "        return amt\n",
    "    if purpose == 'celebrations':\n",
    "        if random.random() < 0.10:  # occasional loan for larger celebration\n",
    "            return random.randint(250, 600)\n",
    "        else:\n",
    "            return random.randint(120, 300)\n",
    "    if purpose == 'emergency':\n",
    "        # Bias to medium range\n",
    "        return random.randint(600, 2000)\n",
    "    if purpose == 'childcare':\n",
    "        return random.randint(400, 1200)\n",
    "    # default\n",
    "    bucket, amt = weighted_choice(loan_ranges)\n",
    "    return amt\n",
    "\n",
    "\n",
    "def build_user_request(purpose: str, amount: int, relationship: str, gift: bool):\n",
    "    templates = [\n",
    "        \"Hey, could you help me with ${amt} for a {purpose} expense?\",\n",
    "        \"I’m hoping you might be able to spot me ${amt} related to {purpose}.\",\n",
    "        \"Could you lend me ${amt}? It’s for {purpose} and I’d really appreciate it.\",\n",
    "        \"Any chance you can help with ${amt} toward {purpose}?\",\n",
    "        \"I could use ${amt} to cover some {purpose} costs—can you help?\",\n",
    "    ]\n",
    "    base = random.choice(templates).format(amt=amount, purpose=purpose)\n",
    "    if not gift:\n",
    "        # Add repayment intent line\n",
    "        repayment_lines = [\n",
    "            \"I can start repayments next month.\",\n",
    "            \"I’d like to pay it back over the next few months.\",\n",
    "            \"Happy to set a schedule that works for you.\",\n",
    "            \"I can do equal monthly payments if approved.\",\n",
    "        ]\n",
    "        base += \" \" + random.choice(repayment_lines)\n",
    "    else:\n",
    "        gift_lines = [\n",
    "            \"If this can be a gift I’ll pay it forward.\",\n",
    "            \"If you’re okay treating it as a gift, I’m grateful.\",\n",
    "            \"Totally understand if not, but hoping this can be a gift.\",\n",
    "        ]\n",
    "        if random.random() < 0.5:\n",
    "            base += \" \" + random.choice(gift_lines)\n",
    "    return base\n",
    "\n",
    "\n",
    "def build_assistant_completion(status: str, gift: bool, amount: int, purpose: str, relationship: str):\n",
    "    currency = 'USD'\n",
    "    if status == 'approved':\n",
    "        opener = random.choice(empathy_openers) + ' ' + random.choice(positive_reassurance)\n",
    "    elif status == 'declined':\n",
    "        opener = random.choice(decline_warmth)\n",
    "    else:\n",
    "        opener = random.choice(pending_warmth)\n",
    "\n",
    "    lines = [opener]\n",
    "    lines.append(f\"Approval: {status}\")\n",
    "    # Mandatory Terms header\n",
    "    terms = [f\"- Amount: {amount} {currency}\"]\n",
    "    # Disbursement logic\n",
    "    disburse_options = ['within 2 days (bank transfer)','same day (mobile transfer)','this week (bank transfer)','within 24 hours (instant)']\n",
    "    terms.append(f\"- Disbursement: {random.choice(disburse_options)}\")\n",
    "\n",
    "    if not gift and status == 'approved':\n",
    "        # Repayment schedule based on amount\n",
    "        if amount <= 600:\n",
    "            sched_options = ['3 monthly payments','4 monthly payments','6 biweekly payments']\n",
    "        elif amount <= 2000:\n",
    "            sched_options = ['6 monthly payments','9 monthly payments','12 monthly payments']\n",
    "        else:\n",
    "            sched_options = ['12 monthly payments','15 monthly payments','18 monthly payments']\n",
    "        terms.append(f\"- Repayment Schedule: {random.choice(sched_options)} starting next month\")\n",
    "        # Interest occasionally\n",
    "        if random.random() < INTEREST_RATE_PROB:\n",
    "            terms.append(f\"- Interest: {random.randint(1,3)}% symbolic family rate\")\n",
    "        else:\n",
    "            terms.append(\"- Interest: 0% (family support)\")\n",
    "        # Grace\n",
    "        if amount <= 600:\n",
    "            if random.random() < 0.4:\n",
    "                terms.append(\"- Grace: 2 weeks flexible\")\n",
    "        elif amount <= 2000:\n",
    "            if random.random() < 0.6:\n",
    "                terms.append(\"- Grace: 1 month flexible\")\n",
    "        else:\n",
    "            terms.append(\"- Grace: 1 month flexible\")\n",
    "        # Reminder Style\n",
    "        terms.append(f\"- Reminder Style: {random.choice(reminder_styles)}\")\n",
    "\n",
    "    notes = []\n",
    "    if gift:\n",
    "        notes.append(\"Treated as a gift—no repayment expected.\")\n",
    "    if status == 'pending':\n",
    "        notes.append(\"Need confirmation of exact timing and any other contributions.\")\n",
    "    if status == 'declined':\n",
    "        notes.append(\"Please reach out again if circumstances change; I want to help where I can.\")\n",
    "\n",
    "    lines.append('Terms:')\n",
    "    lines.extend(terms)\n",
    "    if notes:\n",
    "        lines.append('Notes: ' + ' '.join(notes))\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Build label list\n",
    "labels = []\n",
    "for (status, gift), c in counts.items():\n",
    "    labels.extend([(status, gift)] * c)\n",
    "random.shuffle(labels)\n",
    "\n",
    "examples = []\n",
    "for i, (status, gift) in enumerate(labels):\n",
    "    purpose = random.choice(purpose_categories)\n",
    "    relationship = random.choice(relationships)\n",
    "    amount = choose_amount(gift, purpose)\n",
    "    user_req = build_user_request(purpose, amount, relationship, gift)\n",
    "    prompt_context = f\"User Request:\\n{user_req}\\nContext:\\nRelationship: {relationship}\\nPurpose: {purpose}\\nGift Classification: {'yes' if gift else 'no'}\"\n",
    "    completion = build_assistant_completion(status, gift, amount, purpose, relationship)\n",
    "    record = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': prompt_context},\n",
    "            {'role': 'assistant', 'content': completion}\n",
    "        ]\n",
    "    }\n",
    "    examples.append(record)\n",
    "\n",
    "# Split\n",
    "train_size = int(TOTAL * SPLIT_TRAIN)\n",
    "train_set = examples[:train_size]\n",
    "val_set = examples[train_size:]\n",
    "\n",
    "FT_DIR = pathlib.Path('fine_tuning')\n",
    "FT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "train_path = FT_DIR / 'family_lending_chat_train.jsonl'\n",
    "val_path = FT_DIR / 'family_lending_chat_val.jsonl'\n",
    "\n",
    "with open(train_path, 'w', encoding='utf-8') as f:\n",
    "    for rec in train_set:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "with open(val_path, 'w', encoding='utf-8') as f:\n",
    "    for rec in val_set:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Wrote', len(train_set), 'train and', len(val_set), 'validation examples.')\n",
    "\n",
    "# Quick distribution check\n",
    "from collections import Counter\n",
    "ctr = Counter((rec['messages'][1]['content'].split('\\n')[1].split(': ')[1], 'yes' if 'Gift Classification: yes' in rec['messages'][0]['content'] else 'no') for rec in examples)\n",
    "print('Class distribution (status,gift):')\n",
    "for k,v in ctr.items():\n",
    "    print(k, v)\n",
    "\n",
    "examples[0]  # show one sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d08a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (Placeholder) Fine-Tune Process Outline for Colab + Ollama style adapter\n",
    "# This cell will later be expanded to actually launch a QLoRA / LoRA style fine-tune using an 8B base (e.g., llama3:8b) if feasible.\n",
    "# High-level steps (will add executable code after confirming environment in Colab):\n",
    "# 1. !pip install transformers peft datasets accelerate bitsandbytes sentencepiece\n",
    "# 2. Load base model in 4-bit (bnb.int4) with transformers.\n",
    "# 3. Tokenize chat examples -> apply a chat template or manual join (system(optional) + user + assistant).\n",
    "# 4. Apply LoRA config (rank ~ 32, alpha 16, dropout 0.05) with target modules depending on architecture.\n",
    "# 5. Train with gradient checkpointing, batch size adaptation, and eval on validation set.\n",
    "# 6. Save adapter weights; optionally merge for export.\n",
    "# 7. Convert to GGUF / create Ollama Modelfile referencing the adapter or merged model.\n",
    "# 8. Test sample generations locally via ollama run.\n",
    "\n",
    "print('Fine-tune outline placeholder ready. Expand when running in Colab environment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab7fd90",
   "metadata": {},
   "source": [
    "## 5. Fine-Tune Outline (To Implement in Colab)\n",
    "Guides setting up a QLoRA/LoRA run on a base model (e.g., llama3:8b) using 4-bit loading for free-tier GPU constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe826b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (Placeholder) Evaluation & Sample Generation\n",
    "# After fine-tuning, load adapter/merged model and run sample prompts to qualitatively assess.\n",
    "# - Check gift vs non-gift formatting consistency\n",
    "# - Ensure optional fields omitted for gifts\n",
    "# - Spot check declined/pending tone warmth\n",
    "# - Possibly compute simple regex-based metric: required headers present.\n",
    "\n",
    "print('Add evaluation logic after training step implemented.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b407e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save Artifacts / Outputs (placeholder)\n",
    "# When training is complete, implement logic here to:\n",
    "# - Save adapter weights (e.g., ./fine_tuning/adapter)\n",
    "# - Optionally merge LoRA into base model (careful with Colab RAM)\n",
    "# - Export a Modelfile snippet for Ollama referencing merged or adapter path\n",
    "# - Write summary stats (counts, example) to a JSON report\n",
    "\n",
    "print('Artifact saving placeholder ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779537f1",
   "metadata": {},
   "source": [
    "## 6. Evaluation & Sample Generation\n",
    "Will load the fine-tuned adapter/merged model to run qualitative checks and simple structural validation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d32e2",
   "metadata": {},
   "source": [
    "## 7. Save Artifacts / Outputs\n",
    "Persist key outputs (trained adapter, merged model if desired, dataset stats, sample generations) and prepare an Ollama Modelfile snippet for local deployment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
